{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis-compliance_paragraphs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikelabadie/Earnings_Call_Transcripts/blob/master/analysis_compliance_paragraphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EBSKtWKn7k-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read Call Pickle and Build Meta-data and Text DataFrames"
      ]
    },
    {
      "metadata": {
        "id": "TwdjbLSwSX6I",
        "colab_type": "code",
        "outputId": "b630e0a5-51d2-4825-fd15-9a546701da76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# import the call dataset\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if os.path.exists(\"/content/gdrive/My Drive/School/DATS 6450 - NLP/Project/ProcessedCallsPickleUpdated\"):\n",
        "    pfile = open(\"/content/gdrive/My Drive/School/DATS 6450 - NLP/Project/ProcessedCallsPickleUpdated\", \"rb\")\n",
        "    calls = pickle.load(pfile)                      \n",
        "    pfile.close()\n",
        "    \n",
        "metadata={link:data[\"metadata\"] for link, data in calls.items()}\n",
        "df_metadata = pd.DataFrame.from_dict(metadata, orient=\"index\")\n",
        "\n",
        "speakers = {}\n",
        "for i, (key, value) in enumerate(metadata.items()):\n",
        "  if not(value.get(\"call participants\") is None):\n",
        "    speakers[key] = value[\"call participants\"][[\"Speaker\",\"Title\"]]\n",
        "\n",
        "text={link:data[\"text\"] for link, data in calls.items()}\n",
        "df_text = pd.DataFrame.from_dict(text, orient=\"index\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ebvucucuqja4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Mean Num Prepared Remarks Paragraphs per Call"
      ]
    },
    {
      "metadata": {
        "id": "0sq5oi4AqmGd",
        "colab_type": "code",
        "outputId": "4fede294-734f-4cc9-cf5a-5572f84e1ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "num_prep_para = []\n",
        "for _, row in  df_metadata.dropna(subset=[\"ticker\",\"period\",\"call date\"]).iterrows():\n",
        "  prepared_remarks = text.get(row.name)\n",
        "  prepared_remarks = prepared_remarks[(prepared_remarks[\"Call Section\"]==\"Prepared Remarks\")&(prepared_remarks[\"Speaker\"]!=\"Operator\")]\n",
        "  num_prep_para.append(prepared_remarks.shape[0])\n",
        "  \n",
        "print(np.mean(num_prep_para))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40.869980506822614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NO7sjxQ77sLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tools to Build Corpus"
      ]
    },
    {
      "metadata": {
        "id": "IWTcC6-VJ_80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pyLDAvis\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sy5TZPEl135W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "import time\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5_yLqYX7v19",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Corpus"
      ]
    },
    {
      "metadata": {
        "id": "CcDLsJ96rwUe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Get a List of Tickers to Analyze"
      ]
    },
    {
      "metadata": {
        "id": "khyyg1zpTMAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ticker_list = [\"DNKN\",\"SBUX\",\"MCD\",\"QSR\",\"YUM\",\"BLMN\",\"EAT\",\"CMG\",\"CBRL\",\"DRI\",\"DPZ\",\"JACK\",\"PZZA\",\"TXRH\",\"CAKE\",\n",
        "              \"WEN\",\"BH\",\"BH\",\"BJRI\",\"BOJA\",\"TAST\",\"CHUY\",\"PLAY\",\"DFRG\",\"TACO\",\"DENN\",\"DIN\",\"LOCO\",\"FRGI\",\"PBPB\",\n",
        "              \"RRGB\",\"RUTH\",\"SHAK\",\"SONC\",\"HABT\",\"WING\",\"ZOES\",\"ARKR\",\"BURG\",\"SAUC\",\"DAVE\",\"FAT\",\"BDL\",\"GTIM\",\n",
        "              \"KONA\",\"JAX\",\"JMBA\",\"LUB\",\"NATH\",\"NDLS\",\"FRSH\",\"RAVE\",\"STKS\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ujY8Z7t13h2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "call_keys = []\n",
        "call_names = []\n",
        "paragraph_nums = []\n",
        "speakers = []\n",
        "corpus_whole = []\n",
        "call_names_whole = []\n",
        "\n",
        "calls_to_use = df_metadata.dropna(subset=[\"ticker\",\"period\",\"call date\"])[0:5000]\n",
        "#calls_to_use = df_metadata[(df_metadata[\"ticker\"].isin(ticker_list))].dropna(subset=[\"ticker\",\"period\",\"call date\"]).sort_values(by=[\"ticker\"])\n",
        "\n",
        "# loop through each call of interest\n",
        "for _, row in calls_to_use.iterrows():\n",
        "    prepared_remarks = text.get(row.name)\n",
        "    prepared_remarks = prepared_remarks[(prepared_remarks[\"Call Section\"]==\"Prepared Remarks\")&(prepared_remarks[\"Speaker\"]!=\"Operator\")]     \n",
        "    \n",
        "    corpus += list(prepared_remarks[\"Cleaned Text\"])\n",
        "    corpus_whole.append(\" \".join(list(prepared_remarks[\"Cleaned Text\"])))\n",
        "    call_keys += [(row.name, x) for x in prepared_remarks.index.values]\n",
        "    call_names += [row[\"ticker\"] + \" \" + row[\"period\"] + \" \" + str(x) for x in prepared_remarks.index.values]\n",
        "    call_names_whole.append(row[\"ticker\"] + \" \" + row[\"period\"])\n",
        "    paragraph_nums += [x/prepared_remarks.shape[0] for x in prepared_remarks.index.values]\n",
        "    speakers += list(prepared_remarks[\"Speaker\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEzcNUhE71zl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectors"
      ]
    },
    {
      "metadata": {
        "id": "20BLezbMl1ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Find Common Used Phrases at Whole Call Level\n",
        "I'm looking to find phrases said on every call.  Particularly, things like \"forward looking statements\" to help identify phrases that might signify a paragraph is \"mandatory\"."
      ]
    },
    {
      "metadata": {
        "id": "VMXS3MqhcXPF",
        "colab_type": "code",
        "outputId": "30fbfd9e-6826-46ae-c1d0-51fd3bf25b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(2,2), min_df=0.8, binary=True)\n",
        "X = vectorizer.fit_transform(corpus_whole)\n",
        "df = pd.DataFrame(data=X.toarray(), index=call_names_whole, columns=vectorizer.get_feature_names())\n",
        "\n",
        "keywords_by_doc = set(df.columns)\n",
        "\n",
        "print(keywords_by_doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'turn call', 'thank you', 'forward looking', 'looking statement'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EA4IwAfnphtc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Find Phrases at Paragraph Level\n",
        "I'm looking to find phrases that typically occur at least once, but no more than a few times during a call (like \"forward looking statements\")."
      ]
    },
    {
      "metadata": {
        "id": "bR45vsjtzyD5",
        "colab_type": "code",
        "outputId": "5cff1e86-e9bd-4b49-b19c-f7f4940ccb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3), min_df=0.02, max_df=0.075, binary=True)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "df = pd.DataFrame(data=X.toarray(), index=call_names, columns=vectorizer.get_feature_names())\n",
        "df[\"Paragraph Location\"] = paragraph_nums\n",
        "\n",
        "keywords_by_paragraph = set(df.columns)\n",
        "\n",
        "print(df.shape, df.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(204238, 391) Index(['10', '100', '11', '12', '13', '14', '15', '16', '17', '18',\n",
            "       ...\n",
            "       'working', 'world', 'would', 'would like', 'year 2018', 'year ago',\n",
            "       'year over', 'year over year', 'you', 'Paragraph Location'],\n",
            "      dtype='object', length=391)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4J8rTE13i4oD",
        "colab_type": "code",
        "outputId": "1fa12ebf-e0d6-4bc8-e761-9106e10480f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "keywords_by_doc.intersection(keywords_by_paragraph)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'forward looking', 'looking statement', 'thank you', 'turn call'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "cK_tthWPhrib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KMeans Clustering to Classify Compliance Paragraphs\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py"
      ]
    },
    {
      "metadata": {
        "id": "pmrqUYQghqyr",
        "colab_type": "code",
        "outputId": "42a9fe3d-4be3-4feb-c2aa-55dbc703613d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters=3)\n",
        "\n",
        "cols = list(set(df.columns)-set([\"Prediction\"]))\n",
        "cols = list(keywords_by_doc.intersection(keywords_by_paragraph))\n",
        "km.fit(df.loc[:,cols].values)\n",
        "\n",
        "df[\"Prediction\"] = km.labels_\n",
        "low_occurence_class = df[\"Prediction\"].value_counts().sort_values().index[0]\n",
        "compliance_paragraphs = df.loc[df[\"Prediction\"]==low_occurence_class,[\"Prediction\",\"Paragraph Location\"]].index\n",
        "\n",
        "print(df[\"Prediction\"].value_counts().sort_values())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2      5886\n",
            "1     10145\n",
            "0    188207\n",
            "Name: Prediction, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNk65iu_QSgD",
        "colab_type": "code",
        "outputId": "19461de0-4da6-4aa5-ef62-614cdeda6746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "cell_type": "code",
      "source": [
        "compliance_paragraphs[-100:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SSW Q4 2018 2', 'SSW Q4 2018 3', 'MCRB Q4 2018 2', 'MCRB Q4 2018 3',\n",
              "       'SINA Q4 2018 3', 'SCM Q4 2018 3', 'SCM Q4 2018 6', 'TPVG Q4 2018 3',\n",
              "       'TPVG Q4 2018 4', 'WB Q4 2018 4', 'WB Q4 2018 5', 'WMC Q4 2018 5',\n",
              "       'WMC Q4 2018 6', 'WEYS Q4 2018 3', 'YEXT Q4 2018 3', 'YEXT Q4 2018 4',\n",
              "       'YEXT Q4 2018 5', 'ABM Q1 2019 3', 'ALBO Q4 2018 2', 'ALBO Q4 2018 3',\n",
              "       'ALBO Q4 2018 4', 'AEO Q4 2018 2', 'AEO Q4 2018 3', 'AEO Q4 2018 7',\n",
              "       'AOBC Q3 2019 3', 'ABUS Q4 2018 3', 'ARQL Q4 2018 3', 'ARQL Q4 2018 4',\n",
              "       'BLDP Q4 2018 1', 'BKCC Q4 2018 4', 'BKCC Q4 2018 5', 'BURL Q4 2018 4',\n",
              "       'WHD Q4 2018 2', 'CRCM Q4 2018 3', 'CRCM Q4 2018 5', 'CECE Q4 2018 2',\n",
              "       'CECE Q4 2018 3', 'CLDX Q4 2018 2', 'CLDX Q4 2018 3', 'CBPO Q4 2018 4',\n",
              "       'CBPO Q4 2018 5', 'CHUY Q4 2018 2', 'CWEN Q4 2018 4', 'CLPR Q4 2018 4',\n",
              "       'CMTL Q2 2019 4', 'CTK Q4 2018 3', 'CTK Q4 2018 4', 'CTK Q4 2018 5',\n",
              "       'COST Q2 2019 2', 'COST Q2 2019 3', 'BREW Q4 2018 4', 'CYRX Q4 2018 1',\n",
              "       'CYRX Q4 2018 2', 'CULP Q3 2019 3', 'CULP Q3 2019 4', 'CTSO Q4 2018 2',\n",
              "       'CTSO Q4 2018 3', 'DESP Q4 2018 3', 'DXPE Q4 2018 4', 'LOCO Q4 2018 3',\n",
              "       'ERII Q4 2018 3', 'ERII Q4 2018 4', 'FLY Q4 2018 5', 'FRPH Q4 2018 3',\n",
              "       'FSK Q4 2018 6', 'GERN Q4 2018 6', 'GERN Q4 2018 7', 'GERN Q4 2018 8',\n",
              "       'GMRE Q4 2018 4', 'GMRE Q4 2018 6', 'GMRE Q4 2018 7', 'GMRE Q4 2018 8',\n",
              "       'GMRE Q4 2018 10', 'GNC Q4 2018 2', 'GSHD Q4 2018 3', 'GSHD Q4 2018 4',\n",
              "       'HBB Q4 2018 5', 'HCI Q4 2018 4', 'HRB Q3 2019 2', 'HRB Q3 2019 3',\n",
              "       'IGT Q4 2018 3', 'KRP Q4 2018 3', 'KRP Q4 2018 4', 'KR Q4 2018 2',\n",
              "       'LILA Q4 2018 4', 'LILA Q4 2018 5', 'LGF-A Q3 2019 3', 'MRVL Q4 2019 5',\n",
              "       'MLR Q4 2018 3', 'MYRG Q4 2018 5', 'NC Q4 2018 5', 'NSTG Q4 2018 4',\n",
              "       'NRP Q4 2018 2', 'NEWT Q4 2018 4', 'NINE Q4 2018 3', 'NINE Q4 2018 4',\n",
              "       'NVEE Q4 2018 2', 'NVEE Q4 2018 3', 'OCUL Q4 2018 4', 'OCUL Q4 2018 5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "uX9PHmL3vLuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Call Links"
      ]
    },
    {
      "metadata": {
        "id": "HXqVwwUCmloL",
        "colab_type": "code",
        "outputId": "2e548f00-fdfc-476b-bce0-f80b1f878250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(calls_to_use.index.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://www.fool.com/earnings/call-transcripts/2017/10/23/citizens-financial-group-q3-2017-earnings-conferen.aspx'\n",
            " 'https://www.fool.com/earnings/call-transcripts/2017/10/24/illinois-tool-works-itw-q3-2017-earnings-conferenc.aspx'\n",
            " 'https://www.fool.com/earnings/call-transcripts/2017/10/25/3m-mmm-q3-2017-earnings-conference-call-transcript.aspx'\n",
            " ...\n",
            " 'https://www.fool.com/earnings/call-transcripts/2019/01/25/oceanfirst-financial-corp-ocfc-q4-2018-earnings-co.aspx'\n",
            " 'https://www.fool.com/earnings/call-transcripts/2019/01/25/qcr-holdings-inc-qcrh-q4-2018-earnings-conference.aspx'\n",
            " 'https://www.fool.com/earnings/call-transcripts/2019/01/25/resmed-rmd-q2-2019-earnings-conference-call-transc.aspx']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}